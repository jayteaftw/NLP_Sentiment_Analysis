{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 1)\n",
      "(2400, 3631)\n",
      "corpus size 3631\n"
     ]
    }
   ],
   "source": [
    "x_train_file = open(\"x_train.csv\")\n",
    "x_train = []\n",
    "for idx, i in enumerate(x_train_file):\n",
    "    if idx == 0:\n",
    "        continue\n",
    "    x = i.strip().split(\",\")\n",
    "    x = x[0] + \": \" + x[1]\n",
    "    x_train.append(x)\n",
    "\n",
    "y_train_file = open(\"y_train.csv\")\n",
    "y_train = []\n",
    "for idx, i in enumerate(y_train_file):\n",
    "    if idx == 0:\n",
    "        continue\n",
    "    y_train.append(i)\n",
    "\n",
    "y_train = np.asarray(y_train,dtype=int).reshape(len(y_train),1)\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "x_train = vectorizer.fit_transform(x_train)\n",
    "vectorizer.get_feature_names_out()\n",
    "corpus_size = x_train.shape[1]\n",
    "x_train = x_train.toarray()\n",
    "\n",
    "\n",
    "x_val, y_val = None, None \n",
    "print(y_train.shape)\n",
    "print(x_train.shape)\n",
    "print(f'corpus size {corpus_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 3631) (400, 3631)\n",
      "(2000, 1) (400, 1)\n"
     ]
    }
   ],
   "source": [
    "indices = np.random.permutation(x_train.shape[0])\n",
    "training_idx, test_idx = indices[:2000], indices[2000:] #16% Validation, 84% Training\n",
    "x_train, x_val = x_train[training_idx,:], x_train[test_idx,:]\n",
    "y_train, y_val = y_train[training_idx,:], y_train[test_idx,:]\n",
    "\n",
    "print(x_train.shape, x_val.shape)\n",
    "print(y_train.shape, y_val.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LG_Model():\n",
    "    def __init__(self, corpus_size) -> None:\n",
    "        self.W_T = np.random.rand(corpus_size,1)\n",
    "        self.B = 0\n",
    "        self.learning_rate = 0.2\n",
    "    \n",
    "    def sigmoid_activation(self, r):\n",
    "        return 1/(1+np.exp(-r))\n",
    "\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        #print(\"Y shape\", Y.shape)\n",
    "        #print(\"X shape\", X.shape)\n",
    "        #print(\"W shape\", self.W_T.shape)\n",
    "        \n",
    "        m = X.shape[0]\n",
    "        h_x = self.sigmoid_activation(np.dot(X, self.W_T)+self.B)\n",
    "        dw = np.dot(X.T, (h_x - Y))/m\n",
    "        db = np.sum(h_x - Y)/m\n",
    "       \n",
    "        return dw, db\n",
    "    \n",
    "    def predict_prob(self,X):\n",
    "        h_x = self.sigmoid_activation(np.dot(X, self.W_T)+self.B)\n",
    "        return h_x\n",
    "\n",
    "\n",
    "    def predict(self,X):\n",
    "        m = X.shape[0]\n",
    "        h_x = self.sigmoid_activation(np.dot(X, self.W_T)+self.B)\n",
    "        y_pred = np.zeros((m,1))\n",
    "        for i in range(m):\n",
    "            if h_x[i] > 0.5:\n",
    "                y_pred[i] = 1\n",
    "        return y_pred\n",
    "\n",
    "    def save_model(self):\n",
    "        model = {\"W\":self.W_T, \"B\": self.B}\n",
    "        with open(\"model.pkl\", \"wb\") as f:\n",
    "            pickle.dump(model,f)\n",
    "\n",
    "    def load_model(self):\n",
    "        with open(\"model.pkl\", \"rb\") as f:\n",
    "            model = pickle.load(f)\n",
    "        self.W_T = model[\"W\"]\n",
    "        self.B = model[\"B\"]\n",
    "\n",
    "    def train(self,X_train, Y_train, X_val=None, Y_val=None, iterations=10):\n",
    "   \n",
    "        for e in range(iterations):\n",
    "            dw, db = self.forward(X_train,Y_train)\n",
    "\n",
    "            #print(dw.shape, db.shape)\n",
    "            self.W_T -= self.learning_rate * dw\n",
    "            self.B -= self.learning_rate * db\n",
    "\n",
    "            if e%100 == 0:\n",
    "                print(f'Epoch {e} / {iterations}')\n",
    "                if  isinstance(X_val,np.ndarray)  and isinstance(Y_val,np.ndarray):\n",
    "                    y_pred = self.predict(X_val)\n",
    "                    m = X_val.shape[0]\n",
    "                    acc = np.sum(y_pred == Y_val)/m\n",
    "                    print(\"Validation ACC: \", acc)\n",
    "                y_pred = self.predict(X_train)\n",
    "                m = X_train.shape[0]\n",
    "                acc = np.sum(y_pred == Y_train)/m\n",
    "                print(\"Train ACC: \", acc)\n",
    "                print()\n",
    "\n",
    "                self.save_model()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 3631) (2000, 1)\n",
      "Epoch 0 / 3000\n",
      "Validation ACC:  0.48\n",
      "Train ACC:  0.504\n",
      "\n",
      "Epoch 100 / 3000\n",
      "Validation ACC:  0.475\n",
      "Train ACC:  0.5075\n",
      "\n",
      "Epoch 200 / 3000\n",
      "Validation ACC:  0.485\n",
      "Train ACC:  0.5255\n",
      "\n",
      "Epoch 300 / 3000\n",
      "Validation ACC:  0.5075\n",
      "Train ACC:  0.546\n",
      "\n",
      "Epoch 400 / 3000\n",
      "Validation ACC:  0.51\n",
      "Train ACC:  0.5635\n",
      "\n",
      "Epoch 500 / 3000\n",
      "Validation ACC:  0.535\n",
      "Train ACC:  0.5765\n",
      "\n",
      "Epoch 600 / 3000\n",
      "Validation ACC:  0.5525\n",
      "Train ACC:  0.5915\n",
      "\n",
      "Epoch 700 / 3000\n",
      "Validation ACC:  0.565\n",
      "Train ACC:  0.61\n",
      "\n",
      "Epoch 800 / 3000\n",
      "Validation ACC:  0.5775\n",
      "Train ACC:  0.625\n",
      "\n",
      "Epoch 900 / 3000\n",
      "Validation ACC:  0.5825\n",
      "Train ACC:  0.638\n",
      "\n",
      "Epoch 1000 / 3000\n",
      "Validation ACC:  0.5825\n",
      "Train ACC:  0.645\n",
      "\n",
      "Epoch 1100 / 3000\n",
      "Validation ACC:  0.6\n",
      "Train ACC:  0.6555\n",
      "\n",
      "Epoch 1200 / 3000\n",
      "Validation ACC:  0.6075\n",
      "Train ACC:  0.664\n",
      "\n",
      "Epoch 1300 / 3000\n",
      "Validation ACC:  0.6125\n",
      "Train ACC:  0.6695\n",
      "\n",
      "Epoch 1400 / 3000\n",
      "Validation ACC:  0.6225\n",
      "Train ACC:  0.6745\n",
      "\n",
      "Epoch 1500 / 3000\n",
      "Validation ACC:  0.625\n",
      "Train ACC:  0.6835\n",
      "\n",
      "Epoch 1600 / 3000\n",
      "Validation ACC:  0.6275\n",
      "Train ACC:  0.693\n",
      "\n",
      "Epoch 1700 / 3000\n",
      "Validation ACC:  0.63\n",
      "Train ACC:  0.702\n",
      "\n",
      "Epoch 1800 / 3000\n",
      "Validation ACC:  0.6325\n",
      "Train ACC:  0.71\n",
      "\n",
      "Epoch 1900 / 3000\n",
      "Validation ACC:  0.6325\n",
      "Train ACC:  0.717\n",
      "\n",
      "Epoch 2000 / 3000\n",
      "Validation ACC:  0.64\n",
      "Train ACC:  0.724\n",
      "\n",
      "Epoch 2100 / 3000\n",
      "Validation ACC:  0.64\n",
      "Train ACC:  0.731\n",
      "\n",
      "Epoch 2200 / 3000\n",
      "Validation ACC:  0.64\n",
      "Train ACC:  0.736\n",
      "\n",
      "Epoch 2300 / 3000\n",
      "Validation ACC:  0.6425\n",
      "Train ACC:  0.744\n",
      "\n",
      "Epoch 2400 / 3000\n",
      "Validation ACC:  0.6475\n",
      "Train ACC:  0.746\n",
      "\n",
      "Epoch 2500 / 3000\n",
      "Validation ACC:  0.655\n",
      "Train ACC:  0.7535\n",
      "\n",
      "Epoch 2600 / 3000\n",
      "Validation ACC:  0.6575\n",
      "Train ACC:  0.756\n",
      "\n",
      "Epoch 2700 / 3000\n",
      "Validation ACC:  0.6575\n",
      "Train ACC:  0.7615\n",
      "\n",
      "Epoch 2800 / 3000\n",
      "Validation ACC:  0.66\n",
      "Train ACC:  0.766\n",
      "\n",
      "Epoch 2900 / 3000\n",
      "Validation ACC:  0.6675\n",
      "Train ACC:  0.7715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "model = LG_Model(corpus_size)\n",
    "model.train(X_train=x_train, Y_train=y_train, X_val=x_val, Y_val=y_val, iterations=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_file = open(\"x_test.csv\")\n",
    "x_test = []\n",
    "for idx, i in enumerate(x_test_file):\n",
    "    if idx == 0:\n",
    "        continue\n",
    "    x = i.strip().split(\",\")\n",
    "    x = x[0] + \": \" + x[1]\n",
    "    x_test.append(x)\n",
    "x_test = vectorizer.transform(x_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Validation ACC:  0.6675\n",
      "Testing Train ACC:  0.7715\n",
      "[[0.51055266]\n",
      " [0.6262346 ]\n",
      " [0.46332037]\n",
      " [0.27911102]\n",
      " [0.43043685]\n",
      " [0.33779967]\n",
      " [0.27103559]\n",
      " [0.35609782]\n",
      " [0.510062  ]\n",
      " [0.63122819]\n",
      " [0.34832411]\n",
      " [0.47810235]\n",
      " [0.3099395 ]\n",
      " [0.26394491]\n",
      " [0.54870379]\n",
      " [0.33443672]\n",
      " [0.28979178]\n",
      " [0.25101635]\n",
      " [0.44468465]\n",
      " [0.42470182]\n",
      " [0.51701235]\n",
      " [0.4163143 ]\n",
      " [0.35549512]\n",
      " [0.24644516]\n",
      " [0.48470201]\n",
      " [0.60807674]\n",
      " [0.56554683]\n",
      " [0.47448211]\n",
      " [0.35831797]\n",
      " [0.31102313]\n",
      " [0.47105921]\n",
      " [0.39572884]\n",
      " [0.48544887]\n",
      " [0.27161251]\n",
      " [0.5156316 ]\n",
      " [0.56883649]\n",
      " [0.39991264]\n",
      " [0.15099081]\n",
      " [0.48605419]\n",
      " [0.49949325]\n",
      " [0.27791854]\n",
      " [0.34515711]\n",
      " [0.3409223 ]\n",
      " [0.4794213 ]\n",
      " [0.48286522]\n",
      " [0.24182564]\n",
      " [0.27586477]\n",
      " [0.27768682]\n",
      " [0.44396813]\n",
      " [0.35831797]\n",
      " [0.32452169]\n",
      " [0.31520529]\n",
      " [0.7688538 ]\n",
      " [0.39410865]\n",
      " [0.34553802]\n",
      " [0.27524402]\n",
      " [0.41317472]\n",
      " [0.39430913]\n",
      " [0.5082919 ]\n",
      " [0.38878686]\n",
      " [0.50659487]\n",
      " [0.40065834]\n",
      " [0.34795196]\n",
      " [0.28435745]\n",
      " [0.34289921]\n",
      " [0.36546116]\n",
      " [0.29016759]\n",
      " [0.56979487]\n",
      " [0.30037869]\n",
      " [0.52356975]\n",
      " [0.14675436]\n",
      " [0.51546813]\n",
      " [0.35496298]\n",
      " [0.26902718]\n",
      " [0.35137431]\n",
      " [0.34110148]\n",
      " [0.48168716]\n",
      " [0.39335453]\n",
      " [0.58250952]\n",
      " [0.43874148]\n",
      " [0.2467709 ]\n",
      " [0.27960452]\n",
      " [0.48155308]\n",
      " [0.59659019]\n",
      " [0.35804451]\n",
      " [0.4872763 ]\n",
      " [0.56126327]\n",
      " [0.10074972]\n",
      " [0.45994526]\n",
      " [0.20381655]\n",
      " [0.42946276]\n",
      " [0.47192401]\n",
      " [0.32931451]\n",
      " [0.47771558]\n",
      " [0.50575663]\n",
      " [0.50008382]\n",
      " [0.38656857]\n",
      " [0.46133161]\n",
      " [0.38488369]\n",
      " [0.29014437]\n",
      " [0.62954915]\n",
      " [0.42054062]\n",
      " [0.57984985]\n",
      " [0.64618255]\n",
      " [0.55471795]\n",
      " [0.81127203]\n",
      " [0.71656356]\n",
      " [0.8743217 ]\n",
      " [0.20716448]\n",
      " [0.41493152]\n",
      " [0.49450129]\n",
      " [0.31533113]\n",
      " [0.77190382]\n",
      " [0.5622207 ]\n",
      " [0.69649669]\n",
      " [0.51843257]\n",
      " [0.43384766]\n",
      " [0.68480806]\n",
      " [0.60092089]\n",
      " [0.48373542]\n",
      " [0.37387653]\n",
      " [0.66329835]\n",
      " [0.73599371]\n",
      " [0.8754276 ]\n",
      " [0.77551867]\n",
      " [0.8754276 ]\n",
      " [0.50710873]\n",
      " [0.54503078]\n",
      " [0.78555922]\n",
      " [0.59760109]\n",
      " [0.83051315]\n",
      " [0.55578493]\n",
      " [0.62201574]\n",
      " [0.66368501]\n",
      " [0.38040319]\n",
      " [0.42774279]\n",
      " [0.67399502]\n",
      " [0.66286177]\n",
      " [0.42440491]\n",
      " [0.74564779]\n",
      " [0.79721306]\n",
      " [0.66254585]\n",
      " [0.55024877]\n",
      " [0.8315957 ]\n",
      " [0.62371007]\n",
      " [0.56631801]\n",
      " [0.36003041]\n",
      " [0.48024022]\n",
      " [0.78499203]\n",
      " [0.6363463 ]\n",
      " [0.72743834]\n",
      " [0.74212549]\n",
      " [0.47234738]\n",
      " [0.36336359]\n",
      " [0.53263225]\n",
      " [0.52634964]\n",
      " [0.6787146 ]\n",
      " [0.47296298]\n",
      " [0.58103441]\n",
      " [0.73271854]\n",
      " [0.52714897]\n",
      " [0.54981194]\n",
      " [0.42484588]\n",
      " [0.73322463]\n",
      " [0.67796736]\n",
      " [0.57162614]\n",
      " [0.62377138]\n",
      " [0.50810229]\n",
      " [0.6091914 ]\n",
      " [0.50014316]\n",
      " [0.47730631]\n",
      " [0.46758806]\n",
      " [0.47671573]\n",
      " [0.48734249]\n",
      " [0.43282218]\n",
      " [0.62201416]\n",
      " [0.53569549]\n",
      " [0.42437555]\n",
      " [0.67251689]\n",
      " [0.60636744]\n",
      " [0.66938232]\n",
      " [0.2710878 ]\n",
      " [0.58913949]\n",
      " [0.84581919]\n",
      " [0.57457174]\n",
      " [0.68062306]\n",
      " [0.77309498]\n",
      " [0.79050763]\n",
      " [0.52758572]\n",
      " [0.59903095]\n",
      " [0.72169034]\n",
      " [0.54747977]\n",
      " [0.65612861]\n",
      " [0.90041375]\n",
      " [0.59711671]\n",
      " [0.68631299]\n",
      " [0.61883075]\n",
      " [0.52096071]\n",
      " [0.51798068]\n",
      " [0.67479894]\n",
      " [0.35976061]\n",
      " [0.47474924]\n",
      " [0.3210287 ]\n",
      " [0.39181413]\n",
      " [0.22478589]\n",
      " [0.38778782]\n",
      " [0.33400877]\n",
      " [0.17956777]\n",
      " [0.23779804]\n",
      " [0.38077945]\n",
      " [0.43432219]\n",
      " [0.57664256]\n",
      " [0.4560593 ]\n",
      " [0.456162  ]\n",
      " [0.48237596]\n",
      " [0.41656999]\n",
      " [0.3588222 ]\n",
      " [0.36568294]\n",
      " [0.39986981]\n",
      " [0.32849018]\n",
      " [0.55448713]\n",
      " [0.31546109]\n",
      " [0.35935436]\n",
      " [0.28772813]\n",
      " [0.42859678]\n",
      " [0.31103443]\n",
      " [0.43431967]\n",
      " [0.53915422]\n",
      " [0.4714945 ]\n",
      " [0.50963809]\n",
      " [0.22919104]\n",
      " [0.21686092]\n",
      " [0.53501948]\n",
      " [0.41433569]\n",
      " [0.46163136]\n",
      " [0.26669418]\n",
      " [0.14778249]\n",
      " [0.53582223]\n",
      " [0.45896218]\n",
      " [0.21686092]\n",
      " [0.28636657]\n",
      " [0.4043839 ]\n",
      " [0.24504248]\n",
      " [0.33054268]\n",
      " [0.71480354]\n",
      " [0.33413716]\n",
      " [0.28223005]\n",
      " [0.31103443]\n",
      " [0.28416824]\n",
      " [0.38568288]\n",
      " [0.48539908]\n",
      " [0.79270008]\n",
      " [0.43548163]\n",
      " [0.34777306]\n",
      " [0.61041644]\n",
      " [0.38402475]\n",
      " [0.3547622 ]\n",
      " [0.28051468]\n",
      " [0.30482687]\n",
      " [0.42790215]\n",
      " [0.3123573 ]\n",
      " [0.23768291]\n",
      " [0.44328064]\n",
      " [0.31103443]\n",
      " [0.26904483]\n",
      " [0.27644884]\n",
      " [0.31288826]\n",
      " [0.41737817]\n",
      " [0.35683451]\n",
      " [0.40228276]\n",
      " [0.45448134]\n",
      " [0.38173165]\n",
      " [0.6136903 ]\n",
      " [0.49607358]\n",
      " [0.44837118]\n",
      " [0.45784097]\n",
      " [0.25884675]\n",
      " [0.51686315]\n",
      " [0.42975189]\n",
      " [0.31335194]\n",
      " [0.39270605]\n",
      " [0.30634123]\n",
      " [0.49156159]\n",
      " [0.49815572]\n",
      " [0.2785031 ]\n",
      " [0.23879304]\n",
      " [0.42292875]\n",
      " [0.36358493]\n",
      " [0.3875815 ]\n",
      " [0.48438243]\n",
      " [0.44837118]\n",
      " [0.40461616]\n",
      " [0.32791668]\n",
      " [0.31938531]\n",
      " [0.56716999]\n",
      " [0.14518666]\n",
      " [0.40554736]\n",
      " [0.38565716]\n",
      " [0.46032224]\n",
      " [0.40394636]\n",
      " [0.40847824]\n",
      " [0.27586721]\n",
      " [0.30900315]\n",
      " [0.55470396]\n",
      " [0.54554289]\n",
      " [0.44837118]\n",
      " [0.46960539]\n",
      " [0.58893357]\n",
      " [0.40654921]\n",
      " [0.40464982]\n",
      " [0.47503461]\n",
      " [0.5669708 ]\n",
      " [0.42784841]\n",
      " [0.2943026 ]\n",
      " [0.54055759]\n",
      " [0.44165474]\n",
      " [0.33294337]\n",
      " [0.59393305]\n",
      " [0.47075876]\n",
      " [0.61322872]\n",
      " [0.75057914]\n",
      " [0.55595819]\n",
      " [0.53269189]\n",
      " [0.36757843]\n",
      " [0.2986541 ]\n",
      " [0.53306102]\n",
      " [0.82342715]\n",
      " [0.51951654]\n",
      " [0.70179858]\n",
      " [0.57538709]\n",
      " [0.85203586]\n",
      " [0.50787872]\n",
      " [0.39014255]\n",
      " [0.46302452]\n",
      " [0.49284228]\n",
      " [0.41394649]\n",
      " [0.74879051]\n",
      " [0.50034316]\n",
      " [0.42089858]\n",
      " [0.35145251]\n",
      " [0.50625052]\n",
      " [0.37262343]\n",
      " [0.37999413]\n",
      " [0.41837586]\n",
      " [0.80417032]\n",
      " [0.55781536]\n",
      " [0.51150919]\n",
      " [0.52523809]\n",
      " [0.5847478 ]\n",
      " [0.35468411]\n",
      " [0.35627403]\n",
      " [0.2646129 ]\n",
      " [0.63833466]\n",
      " [0.52373824]\n",
      " [0.58151929]\n",
      " [0.36771595]\n",
      " [0.7621044 ]\n",
      " [0.70811099]\n",
      " [0.7566443 ]\n",
      " [0.40995661]\n",
      " [0.49841507]\n",
      " [0.52978672]\n",
      " [0.38714974]\n",
      " [0.48920785]\n",
      " [0.49175284]\n",
      " [0.36675091]\n",
      " [0.73022852]\n",
      " [0.7344917 ]\n",
      " [0.43728368]\n",
      " [0.49507301]\n",
      " [0.58616678]\n",
      " [0.47450346]\n",
      " [0.38938695]\n",
      " [0.68660308]\n",
      " [0.33505335]\n",
      " [0.64025634]\n",
      " [0.60783499]\n",
      " [0.47676633]\n",
      " [0.49369848]\n",
      " [0.44756565]\n",
      " [0.57572241]\n",
      " [0.37366304]\n",
      " [0.49593627]\n",
      " [0.45220186]\n",
      " [0.48087555]\n",
      " [0.64988852]\n",
      " [0.48347124]\n",
      " [0.31989089]\n",
      " [0.69990239]\n",
      " [0.48955958]\n",
      " [0.45081617]\n",
      " [0.57746198]\n",
      " [0.69110622]\n",
      " [0.31103443]\n",
      " [0.53241701]\n",
      " [0.68490365]\n",
      " [0.49198102]\n",
      " [0.60354939]\n",
      " [0.34018622]\n",
      " [0.39983061]\n",
      " [0.30640536]\n",
      " [0.44353681]\n",
      " [0.27140979]\n",
      " [0.50038574]\n",
      " [0.63068048]\n",
      " [0.27941612]\n",
      " [0.45649948]\n",
      " [0.20275766]\n",
      " [0.42193928]\n",
      " [0.44758181]\n",
      " [0.26055742]\n",
      " [0.18036447]\n",
      " [0.42142499]\n",
      " [0.39500994]\n",
      " [0.62322994]\n",
      " [0.51404926]\n",
      " [0.26421145]\n",
      " [0.50524836]\n",
      " [0.47332232]\n",
      " [0.35881413]\n",
      " [0.40599104]\n",
      " [0.45035686]\n",
      " [0.21238739]\n",
      " [0.33561257]\n",
      " [0.61605787]\n",
      " [0.44118522]\n",
      " [0.58741762]\n",
      " [0.49439329]\n",
      " [0.36890839]\n",
      " [0.39722171]\n",
      " [0.21894412]\n",
      " [0.27954267]\n",
      " [0.30136708]\n",
      " [0.27837701]\n",
      " [0.42640563]\n",
      " [0.35818238]\n",
      " [0.33548158]\n",
      " [0.28807875]\n",
      " [0.30682066]\n",
      " [0.51360932]\n",
      " [0.73290142]\n",
      " [0.47264591]\n",
      " [0.45506081]\n",
      " [0.38851471]\n",
      " [0.30841402]\n",
      " [0.45381234]\n",
      " [0.43354646]\n",
      " [0.37008906]\n",
      " [0.73000171]\n",
      " [0.3493022 ]\n",
      " [0.32529658]\n",
      " [0.28668185]\n",
      " [0.58383814]\n",
      " [0.5658092 ]\n",
      " [0.33522253]\n",
      " [0.51616622]\n",
      " [0.41678901]\n",
      " [0.36473857]\n",
      " [0.55646721]\n",
      " [0.56560107]\n",
      " [0.31089909]\n",
      " [0.32443778]\n",
      " [0.62564578]\n",
      " [0.42578052]\n",
      " [0.31189352]\n",
      " [0.3244368 ]\n",
      " [0.27750901]\n",
      " [0.36265171]\n",
      " [0.49771525]\n",
      " [0.36640912]\n",
      " [0.43044925]\n",
      " [0.59693669]\n",
      " [0.54257872]\n",
      " [0.52370162]\n",
      " [0.30596047]\n",
      " [0.43944093]\n",
      " [0.47705159]\n",
      " [0.40766208]\n",
      " [0.28647628]\n",
      " [0.31906454]\n",
      " [0.56185527]\n",
      " [0.44155097]\n",
      " [0.46722924]\n",
      " [0.42019905]\n",
      " [0.44565495]\n",
      " [0.49771525]\n",
      " [0.39869148]\n",
      " [0.43805777]\n",
      " [0.56421339]\n",
      " [0.29250065]\n",
      " [0.22724554]\n",
      " [0.42141345]\n",
      " [0.46508647]\n",
      " [0.51139992]\n",
      " [0.43081562]\n",
      " [0.62902694]\n",
      " [0.32219441]\n",
      " [0.32863071]\n",
      " [0.4750819 ]\n",
      " [0.41345615]\n",
      " [0.70854061]\n",
      " [0.64072259]\n",
      " [0.75090598]\n",
      " [0.4436191 ]\n",
      " [0.52927476]\n",
      " [0.3814263 ]\n",
      " [0.81977451]\n",
      " [0.66237193]\n",
      " [0.64037095]\n",
      " [0.4889863 ]\n",
      " [0.449644  ]\n",
      " [0.55099044]\n",
      " [0.49771525]\n",
      " [0.50957467]\n",
      " [0.38249897]\n",
      " [0.61001949]\n",
      " [0.63121842]\n",
      " [0.50914768]\n",
      " [0.3635253 ]\n",
      " [0.57046714]\n",
      " [0.44067978]\n",
      " [0.54162873]\n",
      " [0.64985817]\n",
      " [0.24509518]\n",
      " [0.63988702]\n",
      " [0.68276666]\n",
      " [0.44699957]\n",
      " [0.58579494]\n",
      " [0.40465893]\n",
      " [0.65980322]\n",
      " [0.4780938 ]\n",
      " [0.75965067]\n",
      " [0.50867218]\n",
      " [0.53959573]\n",
      " [0.47130826]\n",
      " [0.30319306]\n",
      " [0.50867218]\n",
      " [0.39967547]\n",
      " [0.53178601]\n",
      " [0.74200539]\n",
      " [0.47550874]\n",
      " [0.36277315]\n",
      " [0.40231484]\n",
      " [0.72518915]\n",
      " [0.55940245]\n",
      " [0.5661541 ]\n",
      " [0.4968801 ]\n",
      " [0.47296405]\n",
      " [0.79435233]\n",
      " [0.63197366]\n",
      " [0.49739423]\n",
      " [0.40743563]\n",
      " [0.59928062]\n",
      " [0.69618985]\n",
      " [0.42814297]\n",
      " [0.74161196]\n",
      " [0.44254651]\n",
      " [0.47012138]\n",
      " [0.44030238]\n",
      " [0.45915308]\n",
      " [0.60639415]\n",
      " [0.59588394]\n",
      " [0.57698335]\n",
      " [0.5035593 ]\n",
      " [0.5105613 ]\n",
      " [0.60895508]\n",
      " [0.31388519]\n",
      " [0.6510484 ]\n",
      " [0.73520207]\n",
      " [0.383552  ]\n",
      " [0.60875107]\n",
      " [0.60071313]\n",
      " [0.29386612]\n",
      " [0.32732063]\n",
      " [0.43909339]\n",
      " [0.38791255]\n",
      " [0.54428366]\n",
      " [0.65844613]\n",
      " [0.55734766]\n",
      " [0.40021247]\n",
      " [0.58779661]\n",
      " [0.39507432]\n",
      " [0.63238364]\n",
      " [0.39173952]\n",
      " [0.56642371]\n",
      " [0.67881855]\n",
      " [0.68182398]\n",
      " [0.73679917]\n",
      " [0.85887724]\n",
      " [0.46566257]\n",
      " [0.36404584]\n",
      " [0.61918005]\n",
      " [0.37726447]\n",
      " [0.33731254]\n",
      " [0.56276715]\n",
      " [0.6270682 ]\n",
      " [0.4204318 ]\n",
      " [0.48660907]\n",
      " [0.83497429]\n",
      " [0.45727173]]\n"
     ]
    }
   ],
   "source": [
    "model = LG_Model(corpus_size)\n",
    "model.load_model()\n",
    "\n",
    "if  isinstance(x_val,np.ndarray)  and isinstance(y_val,np.ndarray):\n",
    "        y_pred = model.predict(x_val)\n",
    "        m = x_val.shape[0]\n",
    "        acc = np.sum(y_pred == y_val)/m\n",
    "        print(\"Testing Validation ACC: \", acc)\n",
    "\n",
    "y_pred = model.predict(x_train)\n",
    "m = x_train.shape[0]\n",
    "acc = np.sum(y_pred == y_train)/m\n",
    "print(\"Testing Train ACC: \", acc)\n",
    "\n",
    "\n",
    "yprob_test = model.predict_prob(x_test)\n",
    "yprob_test.shape\n",
    "\n",
    "np.savetxt('yprob_test.txt',yprob_test, delimiter=',')\n",
    "print(yprob_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf72eba892f5c395f8c67d4b0644c4498baf453766ce5375cd80f015646971aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
